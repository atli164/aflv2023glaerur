\documentclass{beamer}
\usefonttheme[onlymath]{serif}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{gensymb}
\usepackage{parskip}
\usepackage{mathtools}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{color}
\usepackage{enumerate}
\usepackage{verbatim}
\usepackage{minted}
\parskip 0pt


\DeclareMathOperator{\lcm}{lcm}
\newcommand\floor[1]{\left\lfloor#1\right\rfloor}
\newcommand\ceil[1]{\left\lceil#1\right\rceil}
\newcommand\abs[1]{\left|#1\right|}
\newcommand\p[1]{\left(#1\right)}
\newcommand\sqp[1]{\left[#1\right]}
\newcommand\cp[1]{\left\{#1\right\}}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\renewcommand\Im{\operatorname{Im}}
\renewcommand\Re{\operatorname{Re}}

\usetheme{metropolis}
\graphicspath{{../../shared/}}

\title{Dynamic Programming Part 2}
\author{Atli FF}
\institute{\href{http://ru.is/td}{School of Computer Science} \\[2pt] \href{http://ru.is}{Reykjavík University}}
\titlegraphic{\hfill\includegraphics[height=0.6cm]{../shared/kattis}}
\date{\textbf{Árangursrík forritun og lausn verkefna}}

\begin{document}

\begin{frame}[plain]
    \titlepage
\end{frame}

\begin{frame}[plain]{DP over bitmasks}
    \begin{itemize}
        \item Remember the bitmask representation of subsets?
        \item Each subset of $n$ elements is mapped to an integer in the range $0$, \ldots, $2^{n} - 1$
        \item This makes it easy to do dynamic programming over subsets
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Traveling salesman problem}
    \vspace{10pt}

    \begin{itemize}
        \item We have a graph of $n$ vertices, and a cost $c_{i,j}$ between each pair of vertices $i, j$. We want to find a cycle through all vertices in the graph so that the sum of the edge costs in the cycle is minimal.

        \vspace{5pt}
        \item This problem is NP-Hard, so there is no known deterministic polynomial time algorithm that solves it

        \vspace{10pt}
        \item Simple to do in $O(n!)$ by going through all permutations of the vertices, but that's too slow if $n > 11$

        \vspace{10pt}
        \item Can we go higher if we use dynamic programming?
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Traveling salesman problem}
    \vspace{20pt}
    \begin{itemize}
\item Without loss of generality, assume we start and end the cycle at vertex $0$
    \vspace{10pt}

\item Let $\mathrm{tsp}(i, S)$ represent the cheapest way to go through all vertices in the graph and back to vertex $0$, if we're currently at vertex $i$ and we've already visited the vertices in the set $S$

    \vspace{20pt}
\item Base case: $\mathrm{tsp}(i, \textrm{all vertices}) = c_{i,0}$
\item Otherwise $\mathrm{tsp}(i, S) = \mathrm{min}_{\ j \not\in S\ } \{\ c_{i,j} + \mathrm{tsp}(j, S \cup \{j\})\ \}$
    \end{itemize}
\end{frame}

\begin{frame}[plain,fragile]{Traveling salesman problem}
    \begin{minted}[fontsize=\scriptsize]{cpp}
const int N = 20;
const int INF = 100000000;
int c[N][N];
int mem[N][1<<N];
memset(mem, -1, sizeof(mem));
int tsp(int i, int S) {
    if (S == ((1 << N) - 1)) {
        return c[i][0];
    }
    if (mem[i][S] != -1) {
        return mem[i][S];
    }
    int res = INF;
    for (int j = 0; j < N; j++) {
        if (S & (1 << j))
            continue;
        res = min(res, c[i][j] + tsp(j, S | (1 << j)));
    }

    mem[i][S] = res;
    return res;
}
    \end{minted}
\end{frame}

\begin{frame}[plain,fragile]{Traveling salesman problem}
    \vspace{30pt}
    \begin{itemize}
\item Then the optimal solution can be found as follows:
    \end{itemize}

    \vspace{20pt}
    \begin{minted}{cpp}
printf("%d\n", tsp(0, 1<<0));
    \end{minted}
\end{frame}

\begin{frame}[plain]{Traveling salesman problem}
    \vspace{30pt}
    \begin{itemize}
        \item Time complexity?
        \vspace{10pt}
        \item There are $n \times 2^n$ possible inputs
        \item Each input is computed in $O(n)$ assuming recursive calls are $O(1)$
        \item Total time complexity is $O(n^2 2^n)$
            \vspace{10pt}
        \item Now $n$ can go up to about $20$
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Subset sum problem}
    \vspace{10pt}

    \begin{itemize}
        \item Another common dynamic programming task is known as the subset sum problem. 
        
        \item Given $n$ positive integers $a_1, \dots, a_n$ find if there is a subset with sum $c$. Variants also include finding the sum closest to $c$, greatest sum not exceeding $c$ and so on.
        
        \item The naïve solution here would involve checking every subset, which if done efficiently (for example with gray codes) takes $O(2^n)$, which is quite slow.
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Subset sum problem}
    \vspace{10pt}

    \begin{itemize}
        \item Let $f(i, s)$ be a boolean function answering whether there exists a subset of $a_1, \dots, a_i$ with sum $s$.
        
        \item Then      
        \[f(i, s) = \begin{cases}\texttt{true} \text{ if } i = s = 0 \\ \texttt{false} \text{ if } i = 0, s \neq 0 \\ \texttt{false} \text{ if } s < 0 \\ f(i - 1, j) \texttt{ or } f(i - 1, j - a_i) \text{ otherwise} \end{cases}\]
        
        \item The different variants can then be read from the values of $f$. Each state takes $O(1)$ to compute, and there are $n(a_1 + \dots + a_n)$ states. Denoting the sum by $\Sigma$ this makes our time complexity $O(n\Sigma)$, which isn't great, but is often better than $O(2^n)$.
    \end{itemize}
\end{frame}

\begin{frame}[plain,fragile]{Subset sum problem}
    \begin{minted}[fontsize=\scriptsize]{cpp}
const int N = 20;
const int SIGMA = 10000;
int a[N];
int dp[N][SIGMA]; 
// use int so -1 is unmemoized
// 0 and 1 are the bools as usual
bool subsetsum(int i, int s) {
    if(i < 0) return s == 0;
    if(s < 0) return false;
    if(dp[i][s] != -1) return dp[i][s];
    return dp[i][s] = subsetsum(i - 1, s) || subsetsum(i - 1, s - a[i]);
}
    \end{minted}
\end{frame}

\begin{frame}[plain]{Subset sum problem - variant}
    \vspace{10pt}

    \begin{itemize}
        \item Say we want to find the most even way to split the numbers into two groups, that is to say in a way that minimizes the difference of the sums of the two groups.
        
        \item Furthermore we want to actually output these numbers rather than just the difference in sum.
        
        \item We can use the subset sum solution to do this, simply adding a table that keeps track of what choices we made at what point.
    \end{itemize}
\end{frame}

\begin{frame}[plain,fragile]{Subset sum problem}
    \begin{minted}[fontsize=\scriptsize]{cpp}
#include<bits/stdc++.h>
using namespace std;
vector<int> a;
vector<vector<int>> dp, mv;
bool subsetsum(int i, int s) {
	if(i < 0) return s == 0;
	if(s < 0) return false;
    if(dp[i][s] != -1) return dp[i][s];
    dp[i][s] = 0;
    if(subsetsum(i - 1, s)) {
        dp[i][s] = 1;
        mv[i][s] = 1;
    } else if(subsetsum(i - 1, s - a[i])) {
        dp[i][s] = 1;
        mv[i][s] = 0;
    }
	return dp[i][s];
}
    \end{minted}
\end{frame}

\begin{frame}[plain,fragile]{Subset sum problem}
    \begin{minted}[fontsize=\scriptsize]{cpp}
int main() {
	int n, sm = 0; cin >> n;
	a = vector<int>(n);
	for(int i = 0; i < n; ++i)
		cin >> a[i], sm += a[i];
	dp = mv = vector<vector<int>>(n, vector<int>(sm, -1));
	int bst = sm / 2;
	while(!subsetsum(n - 1, bst)) bst--;
	vector<bool> group1(n, false);
	for(int i = n - 1; i >= 0; --i) {
		if(!mv[i][bst]) {
			group1[i] = true;
			bst -= a[i];
		}
	}
	cout << "Difference: " << abs(bst - (sm - bst)) << '\n';
	cout << "Group 1: ";
	for(int i = 0; i < n; ++i) if(group1[i]) cout << a[i] << ' ';
	cout << "\nGroup 2: ";
	for(int i = 0; i < n; ++i) if(!group1[i]) cout << a[i] << ' ';
	cout << '\n';
}
    \end{minted}
\end{frame}

\begin{frame}[plain]{Multidimensional DP comment}
    \vspace{10pt}

    \begin{itemize}
		\item The order in which you put the dimensions in a multidimensional dp can affect the running time.
		
		\item This is due to cache locality, so if you are fetching sequentially from one dimension and not the other, this can make one order faster.    
    
        \item Usually it doesn't matter, but in a few cases it might.
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Knapsack problem}
    \vspace{10pt}

    \begin{itemize}
        \item The subset sum problem time complexity is exponential, as the sums of the numbers is exponential in the size of the actual input. 
        
        \item Among similar "hard" problems (in terms of time complexity) is the knapsack problem.
        
        \item We have $n$ items, each with some value and some weight. We also have a knapsack with a maximum weight capacity and want to maximize the value with respect to this condition.
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Knapsack problem}
    \vspace{10pt}

    \begin{itemize}
        \item We can once more use dynamic programming to solve this.
        
        \item We let $f(i, j)$ be the maximum value we can get from the first $i$ items if our maximum weight is $j$.
       
       	\item Let $v_1, \dots, v_n$ be the values and $w_1, \dots, w_n$ the weights. Then 	
       	\[f(i, j) = \begin{cases}-\infty \text{ if } j < 0\\0 \text{ otherwise if } i = 0\\ \operatorname{max}(f(i - 1, j), f(i - 1, j - w_i) + v_i) \text{ otherwise}\end{cases}\]
       	\item The time complexity is then $O(nS)$ where $S$ is the sum of the weights.
       	\item We'll leave translating this into code as an exercise.
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Egg dropping problem}
    \vspace{10pt}

    \begin{itemize}
        \item The previous problems are all very well known and classic in computer science. Let us also take a slightly less common example called the egg dropping problem.
        
        \item We have a building with $k$ floors and we wish to figure out from which floor we have to drop an egg so it breaks. I.e. for some $x$ dropping it from the $x$-th floor the egg will break, but dropping it from the $(x-1)$-st floor the egg won't break it.
        
        \item If we have $n$ eggs, how few trials can we get away with in the worst case?
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Egg dropping problem}
    \vspace{10pt}

    \begin{itemize}
        \item Say we drop the egg from a floor $y$. 
        
        \item If the egg breaks, we only need to check floors $< y$ and have one less egg. This is essentially the same problem again but with $y - 1$ floors and $n - 1$ eggs.
        
        \item If the egg doesn't break we only need to check floors $> y$, so the problem is again the same with $k - y$ floors and $n$ eggs.
        
        \item Since we are looking at the worst case, our result is the worse of these two.
        
        \item Since we can choose any $y$, we take the best result among all $y$.
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Egg dropping problem}
    \vspace{10pt}

    \begin{itemize}
        \item Let $f(n, k)$ be the minimum number of trials for $n$ eggs and $k$ floors. 
        \item We note that if we have one egg, we must always go through the floors in order since we can't afford to break an egg.
        \item All together this gives us
        \[f(i, j) = \begin{cases}1 \text{ if } k = 1 \\0 \text{ if } k = 0\\k \text{ if } i = 1\\ \min_{1 \leq x \leq k} 1 + \max(f(i - 1, x - 1), f(i, j - x))\end{cases}\]
        \item We see that this takes $O(k)$ per state and we have $O(nk)$ states, so the time complexity is $O(nk^2)$.
    \end{itemize}
\end{frame}

\begin{frame}[plain]{Egg dropping problem}
    \vspace{10pt}

    \begin{itemize}
        \item As a side note, this can also be solved in $O(nk)$ with a different dynamic programming approach. Try considering calculating the maximum number of floors you can check with $n$ eggs and $k$ trials using dynamic programming.
        
        \item Using some more clever ideas this can even be brought down to $O(n\log(k))$, but we won't need this here.
    \end{itemize}
\end{frame}

% Fleiri dæmi
% Binary lifting / sparse table
% DP optimization (LIS?)

\end{document}

